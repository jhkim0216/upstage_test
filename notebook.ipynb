{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF 문서 분석 및 텍스트 추출\n",
    "\n",
    "이 노트북은 PDF 문서에서 제목과 본문을 추출하고 구조화하는 코드를 포함합니다.\n",
    "\n",
    "## 주요 기능\n",
    "1. 제목 정제 (TitleCleaner)\n",
    "2. 제목 매칭 (TitleMatcher)\n",
    "3. PDF 처리 (PDFProcessor)\n",
    "\n",
    "## 필요한 라이브러리 설치\n",
    "```bash\n",
    "pip install PyMuPDF\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from typing import List, Optional, Tuple, Dict, Any"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. TitleCleaner 클래스\n",
    "제목 텍스트를 정제하는 클래스입니다. 다양한 패턴의 제목을 정규화하고 불필요한 요소를 제거합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class TitleCleaner:\n",
    "    \"\"\"제목 정제를 담당하는 클래스\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def clean_title(text: str) -> str:\n",
    "        \"\"\"제목 텍스트를 정제하는 메서드\"\"\"\n",
    "        # >>>> 로 시작하는 부분 제거\n",
    "        text = re.sub(r'^>>>>\\s*', '', text)\n",
    "        \n",
    "        # 앞의 숫자(01., 1. 등)로 시작하는 경우만 제거\n",
    "        if not (re.match(r'^\\d{4}년', text) or re.match(r'^제\\s*\\d+\\s*[장절]', text)):\n",
    "            text = re.sub(r'^\\d+\\.?\\s*', '', text)\n",
    "        \n",
    "        text = TitleCleaner._normalize_year_patterns(text)\n",
    "        text = TitleCleaner._remove_page_numbers(text)\n",
    "        text = TitleCleaner._process_middle_dots(text)\n",
    "        text = TitleCleaner._normalize_date_patterns(text)\n",
    "        text = TitleCleaner._normalize_spaces(text)\n",
    "        \n",
    "        return text.strip()\n",
    "    \n",
    "    @staticmethod\n",
    "    def _normalize_year_patterns(text: str) -> str:\n",
    "        \"\"\"연도 패턴을 정규화\"\"\"\n",
    "        patterns = [\n",
    "            (r'(\\d{4})\\s*년도', r'\\1년'),  # 2024년도 -> 2024년\n",
    "            (r'(\\d{4})\\s*년(?!\\s*적용)', r'\\1년'),  # 2024 년 -> 2024년\n",
    "            (r'\\'(\\d{2})년(?!\\s*적용)', r'20\\1년'),  # '24년 -> 2024년\n",
    "            (r'^(\\d{2})년(?!\\s*적용)', r'20\\1년'),  # 24년 -> 2024년\n",
    "            (r'(\\d{4})\\s*[~∼]\\s*(\\d{4})\\s*년', r'\\1-\\2년'),  # 2024~2025년 -> 2024-2025년\n",
    "            (r'(\\d{4})\\.(\\d{1,2})\\.(\\d{1,2})', r'\\1년 \\2월 \\3일')  # 2024.1.1 -> 2024년 1월 1일\n",
    "        ]\n",
    "        \n",
    "        for pattern, replacement in patterns:\n",
    "            text = re.sub(pattern, replacement, text)\n",
    "        return text\n",
    "    \n",
    "    @staticmethod\n",
    "    def _remove_page_numbers(text: str) -> str:\n",
    "        \"\"\"페이지 번호와 관련 구분자 제거\"\"\"\n",
    "        patterns = [\n",
    "            r'\\s*[･·ㆍ∙]{2,}\\s*\\d+\\s*$',  # 중간점 + 숫자\n",
    "            r'\\s*\\.{3,}\\s*\\d+$',  # 점(...) + 숫자\n",
    "            r'\\s*\\d+$',  # 숫자\n",
    "            r'\\s*\\.{3,}\\s*'  # 남은 점(...)\n",
    "        ]\n",
    "        \n",
    "        for pattern in patterns:\n",
    "            text = re.sub(pattern, '', text)\n",
    "        return text\n",
    "    \n",
    "    @staticmethod\n",
    "    def _process_middle_dots(text: str) -> str:\n",
    "        \"\"\"중간점 처리\"\"\"\n",
    "        # 단일 중간점(∙) 제거 (장/절 번호 사이)\n",
    "        text = re.sub(r'\\s*[∙]\\s*', ' ', text)\n",
    "        \n",
    "        # 의미있는 중간점 처리\n",
    "        def replace_middle_dot(match):\n",
    "            original = match.group(0)\n",
    "            return ' ･ ' if ' ' in original else '･'\n",
    "            \n",
    "        return re.sub(r'\\s*[･·ㆍ]\\s*', replace_middle_dot, text)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _normalize_date_patterns(text: str) -> str:\n",
    "        \"\"\"날짜 패턴 정규화\"\"\"\n",
    "        text = re.sub(r'(\\d{1,2})\\s*[월]\\s*', r'\\1월 ', text)\n",
    "        text = re.sub(r'(\\d{1,2})\\s*[일]\\s*', r'\\1일 ', text)\n",
    "        return text\n",
    "    \n",
    "    @staticmethod\n",
    "    def _normalize_spaces(text: str) -> str:\n",
    "        \"\"\"공백 정규화\"\"\"\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        text = re.sub(r'\\(\\s*\\)', '', text)  # 빈 괄호 제거\n",
    "        return text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. TitleMatcher 클래스\n",
    "텍스트가 제목과 매칭되는지 확인하는 클래스입니다. 다양한 매칭 방법을 제공합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class TitleMatcher:\n",
    "    \"\"\"제목 매칭을 담당하는 클래스\"\"\"\n",
    "    \n",
    "    def __init__(self, cleaner: TitleCleaner):\n",
    "        self.cleaner = cleaner\n",
    "    \n",
    "    def is_title_match(self, text: str, title: str) -> bool:\n",
    "        \"\"\"텍스트가 제목과 매칭되는지 확인\"\"\"\n",
    "        cleaned_text = self.cleaner.clean_title(text).lower()\n",
    "        cleaned_title = self.cleaner.clean_title(title).lower()\n",
    "        \n",
    "        if not cleaned_text or not cleaned_title:\n",
    "            return False\n",
    "            \n",
    "        # 정확히 일치하는 경우\n",
    "        if cleaned_text == cleaned_title:\n",
    "            return True\n",
    "            \n",
    "        # 페이지 번호와 점(...)을 제거한 후 비교\n",
    "        text_without_page = re.sub(r'\\s*[.·･]{2,}\\s*\\d+\\s*$', '', cleaned_text)\n",
    "        title_without_page = re.sub(r'\\s*[.·･]{2,}\\s*\\d+\\s*$', '', cleaned_title)\n",
    "        \n",
    "        if text_without_page == title_without_page:\n",
    "            return True\n",
    "            \n",
    "        # 번호 패턴 제거 후 비교\n",
    "        text_without_number = re.sub(r'^(?:\\d+\\.)?\\s*', '', text_without_page)\n",
    "        title_without_number = re.sub(r'^(?:\\d+\\.)?\\s*', '', title_without_page)\n",
    "        \n",
    "        if text_without_number == title_without_number:\n",
    "            return True\n",
    "            \n",
    "        return self._check_partial_match(text_without_number, title_without_number)\n",
    "    \n",
    "    def _check_partial_match(self, text: str, title: str) -> bool:\n",
    "        \"\"\"부분 매칭 확인\"\"\"\n",
    "        # 특수문자로 구분된 단어들을 분리\n",
    "        title_words = self._split_with_delimiters(title)\n",
    "        text_words = self._split_with_delimiters(text)\n",
    "        \n",
    "        if len(title_words) > 1:\n",
    "            # 의미있는 단어만 선택 (2글자 이상)\n",
    "            main_words = [w for w in title_words if len(w) > 1]\n",
    "            if not main_words:\n",
    "                return False\n",
    "                \n",
    "            # 매칭되는 단어 수 계산\n",
    "            matched_words = sum(1 for word in main_words if \n",
    "                              any(word in text_part for text_part in text_words))\n",
    "            \n",
    "            # 70% 이상 매칭되면 True\n",
    "            return matched_words >= len(main_words) * 0.7\n",
    "            \n",
    "        # 단일 단어인 경우 정확히 일치해야 함\n",
    "        return text == title\n",
    "    \n",
    "    @staticmethod\n",
    "    def _split_with_delimiters(text: str) -> List[str]:\n",
    "        \"\"\"특수문자로 구분된 단어 분리\"\"\"\n",
    "        # 특수문자로 분리\n",
    "        parts = re.split(r'([-･·ㆍ])', text)\n",
    "        words = []\n",
    "        i = 0\n",
    "        while i < len(parts):\n",
    "            if i + 2 < len(parts) and parts[i+1] in ['-', '･', '·', 'ㆍ']:\n",
    "                words.append(parts[i] + parts[i+1] + parts[i+2])\n",
    "                i += 3\n",
    "            else:\n",
    "                if parts[i].strip():\n",
    "                    words.append(parts[i].strip())\n",
    "                i += 1\n",
    "        return [w for w in words if w and not w in ['-', '･', '·', 'ㆍ']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. PDFProcessor 클래스\n",
    "PDF 문서를 처리하고 목차를 추출하는 클래스입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class PDFProcessor:\n",
    "    \"\"\"PDF 처리를 담당하는 클래스\"\"\"\n",
    "    \n",
    "    def __init__(self, cleaner: TitleCleaner, matcher: TitleMatcher):\n",
    "        self.cleaner = cleaner\n",
    "        self.matcher = matcher\n",
    "    \n",
    "    def extract_toc(self, doc: fitz.Document) -> List[str]:\n",
    "        \"\"\"목차 추출\"\"\"\n",
    "        toc = doc.get_toc()\n",
    "        if toc:\n",
    "            return [title.strip() for _, title, _ in toc]\n",
    "            \n",
    "        return self._extract_toc_manually(doc)\n",
    "    \n",
    "    def _extract_toc_manually(self, doc: fitz.Document) -> List[str]:\n",
    "        \"\"\"수동으로 목차 추출\"\"\"\n",
    "        titles = []\n",
    "        found_titles = set()\n",
    "        current_title_lines = []\n",
    "        \n",
    "        for page in doc:\n",
    "            self._process_page_for_toc(page, titles, found_titles, current_title_lines)\n",
    "            \n",
    "        # 마지막 제목 처리\n",
    "        if current_title_lines and self._is_page_number_format(\" \".join(current_title_lines)):\n",
    "            self._process_current_title(current_title_lines, titles, found_titles)\n",
    "            \n",
    "        return titles\n",
    "    \n",
    "    def _process_page_for_toc(self, page: fitz.Page, titles: List[str], \n",
    "                             found_titles: set, current_title_lines: List[str]) -> None:\n",
    "        \"\"\"페이지 단위 목차 처리\"\"\"\n",
    "        blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "        for block in blocks:\n",
    "            if \"lines\" not in block:\n",
    "                continue\n",
    "                \n",
    "            for line in block[\"lines\"]:\n",
    "                line_text = self._extract_line_text(line)\n",
    "                if not line_text:\n",
    "                    continue\n",
    "                    \n",
    "                self._process_line_for_toc(line_text, titles, found_titles, current_title_lines)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _extract_line_text(line: dict) -> str:\n",
    "        \"\"\"라인에서 텍스트 추출\"\"\"\n",
    "        line_text = \"\"\n",
    "        for span in line[\"spans\"]:\n",
    "            span_text = span[\"text\"].strip()\n",
    "            if span_text:\n",
    "                if line_text and not (line_text.endswith('･') or line_text.endswith('·') or \n",
    "                                    line_text.endswith('ㆍ') or line_text.endswith('-') or\n",
    "                                    line_text.endswith('.')):\n",
    "                    line_text += \" \"\n",
    "                line_text += span_text\n",
    "        return line_text\n",
    "    \n",
    "    def _process_line_for_toc(self, line_text: str, titles: List[str], \n",
    "                             found_titles: set, current_title_lines: List[str]) -> None:\n",
    "        \"\"\"목차용 라인 처리\"\"\"\n",
    "        if self._is_title_start(line_text):\n",
    "            if current_title_lines:\n",
    "                self._process_current_title(current_title_lines, titles, found_titles)\n",
    "                current_title_lines.clear()\n",
    "            current_title_lines.append(line_text)\n",
    "            if self._is_page_number_format(line_text):\n",
    "                self._process_current_title(current_title_lines, titles, found_titles)\n",
    "                current_title_lines.clear()\n",
    "        elif current_title_lines:\n",
    "            current_title_lines.append(line_text)\n",
    "            if self._is_page_number_format(line_text):\n",
    "                self._process_current_title(current_title_lines, titles, found_titles)\n",
    "                current_title_lines.clear()\n",
    "    \n",
    "    def _process_current_title(self, current_title_lines: List[str], \n",
    "                             titles: List[str], found_titles: set) -> None:\n",
    "        \"\"\"현재 제목 처리\"\"\"\n",
    "        if current_title_lines:\n",
    "            full_title = \" \".join(line.strip() for line in current_title_lines)\n",
    "            cleaned_text = self.cleaner.clean_title(full_title)\n",
    "            if cleaned_text and cleaned_text not in found_titles:\n",
    "                titles.append(full_title)\n",
    "                found_titles.add(cleaned_text)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _is_title_start(text: str) -> bool:\n",
    "        \"\"\"제목 시작 패턴 확인\"\"\"\n",
    "        text = text.strip()\n",
    "        return (text.startswith('[') or\n",
    "                re.match(r'^\\d+\\.', text) or\n",
    "                re.match(r'^제\\s*\\d+\\s*[장절]', text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 사용 예제\n",
    "위의 클래스들을 사용하여 PDF 문서를 처리하는 예제입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def process_pdf(pdf_path: str, output_path: str):\n",
    "    \"\"\"PDF 파일을 처리하여 JSON으로 저장\"\"\"\n",
    "    # 클래스 인스턴스 생성\n",
    "    cleaner = TitleCleaner()\n",
    "    matcher = TitleMatcher(cleaner)\n",
    "    processor = PDFProcessor(cleaner, matcher)\n",
    "    \n",
    "    # PDF 문서 열기\n",
    "    doc = fitz.open(pdf_path)\n",
    "    \n",
    "    try:\n",
    "        # 목차 추출\n",
    "        titles = processor.extract_toc(doc)\n",
    "        \n",
    "        # 결과를 JSON으로 저장\n",
    "        result = {\"titles\": titles}\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(result, f, ensure_ascii=False, indent=2)\n",
    "            \n",
    "        print(f\"처리가 완료되어 {output_path}에 저장되었습니다.\")\n",
    "        \n",
    "    finally:\n",
    "        doc.close()\n",
    "\n",
    "# 사용 예제\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_path = \"sample.pdf\"\n",
    "    output_path = \"output.json\"\n",
    "    process_pdf(pdf_path, output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}