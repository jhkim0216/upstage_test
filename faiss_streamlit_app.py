import streamlit as st
import pandas as pd
import numpy as np
import faiss
import pickle
import os
import json
import time
import datetime
from tqdm.auto import tqdm
from dotenv import load_dotenv
from openai import OpenAI

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="FAISS ë²¡í„° ì €ì¥ì†Œ íƒìƒ‰ê¸°",
    page_icon="ğŸ”",
    layout="wide"
)

# prompt í…œí”Œë¦¿ ë¡œë“œ
with open('prompt.txt', 'r', encoding='utf-8') as f:
    PROMPT_TEMPLATE = f.read()

# ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
LOG_DIR = 'logs'
os.makedirs(LOG_DIR, exist_ok=True)

def log_gpt_interaction(question, context, model, response, metadata_only=None, system_prompt=None):
    """
    GPTì™€ì˜ ìƒí˜¸ì‘ìš©ì„ ë¡œê·¸ íŒŒì¼ì— ê¸°ë¡í•©ë‹ˆë‹¤.
    
    Args:
        question (str): ì‚¬ìš©ì ì§ˆë¬¸
        context (str): ì œê³µëœ ì»¨í…ìŠ¤íŠ¸
        model (str): ì‚¬ìš©ëœ ëª¨ë¸
        response (str): GPTì˜ ì‘ë‹µ
        metadata_only (str, optional): ë©”íƒ€ë°ì´í„°ë§Œ ì¶”ì¶œí•œ ì»¨í…ìŠ¤íŠ¸
        system_prompt (str, optional): GPTì—ê²Œ ì „ì†¡ëœ system ë©”ì‹œì§€
    """
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    log_file = os.path.join(LOG_DIR, f"gpt_interaction_{timestamp}.json")
    
    log_data = {
        "timestamp": timestamp,
        "model": model,
        "question": question,
        "system_prompt": system_prompt,  # ì‹¤ì œ ì „ì†¡ëœ system í”„ë¡¬í”„íŠ¸
        "response": response,
        # ë””ë²„ê¹…ìš© ë°ì´í„°
        "full_context": context,
        "metadata_context": metadata_only
    }
    
    with open(log_file, 'w', encoding='utf-8') as f:
        json.dump(log_data, f, ensure_ascii=False, indent=2)
    
    return log_file

class FAISSVectorStore:
    """
    FAISSë¥¼ ì‚¬ìš©í•˜ì—¬ ì„ë² ë”© ë²¡í„°ë¥¼ ì €ì¥í•˜ê³  ê²€ìƒ‰í•˜ëŠ” ë²¡í„° ì €ì¥ì†Œ í´ë˜ìŠ¤
    """
    def __init__(self, index=None, contents=None, metadata=None):
        self.index = index
        self.contents = contents or []
        self.metadata = metadata or []
        self.dimension = 1536  # OpenAI text-embedding-3-small ì„ë² ë”© ì°¨ì›
    
    def load_embeddings(self, embeddings_file, index_file=None, force_recreate=False):
        """
        Excel íŒŒì¼ì—ì„œ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ì„ë² ë”©ì„ ìƒì„±í•œ í›„ FAISS ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            embeddings_file (str): Excel íŒŒì¼ ê²½ë¡œ
            index_file (str): ì €ì¥ëœ FAISS ì¸ë±ìŠ¤ íŒŒì¼ ê²½ë¡œ (ìˆëŠ” ê²½ìš°)
            force_recreate (bool): ê¸°ì¡´ ì¸ë±ìŠ¤ê°€ ìˆì–´ë„ ë¬´ì‹œí•˜ê³  ìƒˆë¡œ ìƒì„±í• ì§€ ì—¬ë¶€
        """
        status_placeholder = st.empty()
        progress_bar = st.progress(0)
        
        status_placeholder.info(f"ì„ë² ë”© íŒŒì¼ '{embeddings_file}'ì„ ë¡œë“œí•˜ëŠ” ì¤‘...")
        progress_bar.progress(10)
        
        # ì´ë¯¸ ì €ì¥ëœ ì¸ë±ìŠ¤ê°€ ìˆëŠ”ì§€ í™•ì¸
        if not force_recreate and index_file and os.path.exists(index_file):
            status_placeholder.info(f"ì €ì¥ëœ FAISS ì¸ë±ìŠ¤ '{index_file}'ì„ ë¡œë“œí•˜ëŠ” ì¤‘...")
            progress_bar.progress(30)
            
            self.index = faiss.read_index(index_file)
            progress_bar.progress(50)
            
            # ë©”íƒ€ë°ì´í„° íŒŒì¼ë„ ë¡œë“œ
            meta_file = index_file + '.meta'
            if os.path.exists(meta_file):
                with open(meta_file, 'rb') as f:
                    meta_data = pickle.load(f)
                    self.contents = meta_data['contents']
                    self.metadata = meta_data['metadata']
                progress_bar.progress(80)
                status_placeholder.success(f"ë©”íƒ€ë°ì´í„°ê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ {len(self.contents)} ê°œì˜ í•­ëª©.")
                progress_bar.progress(100)
                return True
        
        # Excel íŒŒì¼ë¡œë¶€í„° ì„ë² ë”© ìƒì„±
        status_placeholder.info("Excel íŒŒì¼ë¡œë¶€í„° ì„ë² ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤...")
        progress_bar.progress(20)
        
        # Excel íŒŒì¼ ì½ê¸°
        df = pd.read_excel(embeddings_file)
        progress_bar.progress(30)
        
        # ë²¡í„° ì¶”ì¶œ ë° ì¸ë±ìŠ¤ êµ¬ì¶•
        vectors = []
        
        # OpenAI API í‚¤ ì„¤ì •
        api_key = os.environ.get("OPENAI_API_KEY", st.session_state.get('api_key'))
        if not api_key:
            status_placeholder.error("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            progress_bar.progress(0)
            return False
        
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        client = OpenAI(api_key=api_key)
        
        # ë°°ì¹˜ í¬ê¸° ì„¤ì •
        batch_size = 10  # ì‘ì€ ë°°ì¹˜ í¬ê¸°ë¡œ ì‹œì‘
        
        status_placeholder.info(f"ì´ {len(df)} í•­ëª©ì— ëŒ€í•œ ì„ë² ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤...")
        
        for i in range(0, len(df), batch_size):
            batch = df.iloc[i:i + batch_size]
            
            # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
            progress = 30 + (50 * i / len(df))
            progress_bar.progress(int(progress))
            status_placeholder.info(f"ë°°ì¹˜ ì²˜ë¦¬ ì¤‘: {i+1}~{min(i+batch_size, len(df))} / {len(df)}")
            
            for idx, row in batch.iterrows():
                content = row['content']
                metadata = row['metadata']
                
                try:
                    # contentì— ëŒ€í•œ ì„ë² ë”© ìƒì„±
                    content_embedding_response = client.embeddings.create(
                        model="text-embedding-3-small",
                        input=content,
                        encoding_format="float"
                    )
                    content_embedding = content_embedding_response.data[0].embedding
                    
                    # ê²°ê³¼ ì €ì¥
                    vectors.append(content_embedding)
                    self.contents.append(content)
                    self.metadata.append(metadata)
                    
                    # API ìš”ì²­ ê°„ ì§§ì€ ëŒ€ê¸° ì‹œê°„ ì¶”ê°€
                    time.sleep(0.1)
                    
                except Exception as e:
                    status_placeholder.error(f"í•­ëª© {idx+1} ì„ë² ë”© ì‹¤íŒ¨: {str(e)}")
        
        progress_bar.progress(80)
        
        if not vectors:
            status_placeholder.error("ì²˜ë¦¬í•  ë²¡í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            progress_bar.progress(0)
            return False
        
        # NumPy ë°°ì—´ë¡œ ë³€í™˜
        vectors = np.array(vectors).astype('float32')
        
        # FAISS ì¸ë±ìŠ¤ ìƒì„±
        status_placeholder.info("FAISS ì¸ë±ìŠ¤ ìƒì„± ì¤‘...")
        self.dimension = vectors.shape[1]
        self.index = faiss.IndexFlatIP(self.dimension)  # ë‚´ì (ì½”ì‚¬ì¸ ìœ ì‚¬ë„)ì„ ìœ„í•œ ì¸ë±ìŠ¤
        
        # ì •ê·œí™” (ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°ì„ ìœ„í•´)
        faiss.normalize_L2(vectors)
        
        # ì¸ë±ìŠ¤ì— ë²¡í„° ì¶”ê°€
        self.index.add(vectors)
        
        progress_bar.progress(90)
        status_placeholder.success(f"ì´ {len(vectors)} ê°œì˜ ì„ë² ë”©ì´ FAISS ì¸ë±ìŠ¤ì— ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # ì¸ë±ìŠ¤ ë° ë©”íƒ€ë°ì´í„° ì €ì¥
        if index_file:
            status_placeholder.info(f"FAISS ì¸ë±ìŠ¤ë¥¼ '{index_file}'ì— ì €ì¥í•˜ëŠ” ì¤‘...")
            faiss.write_index(self.index, index_file)
            
            # ë©”íƒ€ë°ì´í„° ì €ì¥
            meta_data = {
                'contents': self.contents,
                'metadata': self.metadata
            }
            with open(index_file + '.meta', 'wb') as f:
                pickle.dump(meta_data, f)
            status_placeholder.success(f"FAISS ì¸ë±ìŠ¤ ë° ë©”íƒ€ë°ì´í„°ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        progress_bar.progress(100)
        return True
    
    def search(self, query_embedding, top_k=5):
        """
        ì¿¼ë¦¬ ì„ë² ë”©ê³¼ ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œë¥¼ FAISSë¥¼ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰í•©ë‹ˆë‹¤.
        
        Args:
            query_embedding (ndarray): ê²€ìƒ‰í•  ì¿¼ë¦¬ ì„ë² ë”©
            top_k (int): ë°˜í™˜í•  ìµœëŒ€ ê²°ê³¼ ìˆ˜
            
        Returns:
            list: ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬ëœ ê²°ê³¼ ëª©ë¡
        """
        if self.index is None:
            st.error("ì¸ë±ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return []
        
        # ì¿¼ë¦¬ ì •ê·œí™” (ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ìœ„í•´)
        query_embedding = query_embedding.astype('float32').reshape(1, -1)
        faiss.normalize_L2(query_embedding)
        
        # ê²€ìƒ‰ ìˆ˜í–‰
        start_time = time.time()
        distances, indices = self.index.search(query_embedding, top_k)
        end_time = time.time()
        
        st.info(f"ê²€ìƒ‰ ì™„ë£Œ (ì†Œìš” ì‹œê°„: {end_time - start_time:.4f}ì´ˆ)")
        
        # ê²°ê³¼ êµ¬ì„±
        results = []
        for i, (dist, idx) in enumerate(zip(distances[0], indices[0])):
            if idx >= 0 and idx < len(self.contents):  # ìœ íš¨í•œ ì¸ë±ìŠ¤ì¸ì§€ í™•ì¸
                results.append({
                    'content': self.contents[idx],
                    'metadata': self.metadata[idx],
                    'similarity': float(dist)  # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ (ë†’ì„ìˆ˜ë¡ ìœ ì‚¬)
                })
        
        return results

def get_embedding(text, model="text-embedding-3-small"):
    """
    OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ì˜ ì„ë² ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        text (str): ì„ë² ë”©í•  í…ìŠ¤íŠ¸
        model (str): ì„ë² ë”© ëª¨ë¸ ì´ë¦„
        
    Returns:
        ndarray: ìƒì„±ëœ ì„ë² ë”© ë²¡í„°
    """
    api_key = os.environ.get("OPENAI_API_KEY", st.session_state.get('api_key'))
    if not api_key:
        st.error("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return np.zeros(1536)  # ê¸°ë³¸ ì°¨ì›ì˜ ë¹ˆ ë²¡í„° ë°˜í™˜
    
    # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    client = OpenAI(api_key=api_key)
    
    try:
        with st.spinner("ì„ë² ë”© ìƒì„± ì¤‘..."):
            response = client.embeddings.create(
                model=model,
                input=text,
                encoding_format="float"
            )
        return np.array(response.data[0].embedding)
    except Exception as e:
        st.error(f"ì„ë² ë”© ìƒì„± ì˜¤ë¥˜: {str(e)}")
        return np.zeros(1536)

def format_metadata(metadata_str):
    """ë©”íƒ€ë°ì´í„° ë¬¸ìì—´ì„ í¬ë§·íŒ…í•˜ì—¬ í‘œì‹œí•©ë‹ˆë‹¤."""
    try:
        # ê°„ë‹¨í•œ í˜•ì‹í™”ë¥¼ ìœ„í•œ ê¸°ë³¸ ì²˜ë¦¬
        lines = metadata_str.split('\n')
        formatted_text = ""
        for line in lines:
            if line.strip().startswith("id:") or line.strip().startswith("page:"):
                formatted_text += f"**{line.strip()}**\n\n"
            elif "page_content" in line:
                formatted_text += f"**{line.strip()}**\n"
            else:
                formatted_text += f"{line}\n"
        return formatted_text
    except:
        return metadata_str

def generate_answer(question, context, client, model="gpt-4o"):
    """
    OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ RAG ê¸°ë°˜ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        question (str): ì‚¬ìš©ìì˜ ì§ˆë¬¸
        context (str): ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì¶”ì¶œí•œ ì»¨í…ìŠ¤íŠ¸
        client (OpenAI): OpenAI API í´ë¼ì´ì–¸íŠ¸
        model (str): ì‚¬ìš©í•  ì–¸ì–´ ëª¨ë¸
        
    Returns:
        str: ìƒì„±ëœ ë‹µë³€
    """
    try:
        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì— ì§ˆë¬¸ê³¼ ì»¨í…ìŠ¤íŠ¸ì˜ metadata ì‚½ì…
        # contextì—ì„œ metadataë§Œ ì¶”ì¶œ
        metadata_only = ""
        
        # contextëŠ” ì´ë¯¸ ë¬¸ìì—´ì´ë¯€ë¡œ íŒŒì‹±í•  í•„ìš” ì—†ì´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        # ì›ë³¸ ë¬¸ì„œì˜ ë©”íƒ€ë°ì´í„° ë¶€ë¶„ë§Œ ì¶”ì¶œ
        metadata_lines = []
        lines = context.split('\n')
        for i, line in enumerate(lines):
            if line.strip().startswith("ë©”íƒ€ë°ì´í„°:"):
                # ë©”íƒ€ë°ì´í„° í–‰ì„ ì°¾ì•˜ìœ¼ë©´, ê·¸ ë‹¤ìŒ í–‰ë¶€í„° ë‹¤ìŒ "ë‚´ìš©:" ë˜ëŠ” "ë¬¸ì„œ"ê°€ ë‚˜ì˜¬ ë•Œê¹Œì§€ ì¶”ê°€
                j = i + 1
                while j < len(lines) and not (lines[j].strip().startswith("ë‚´ìš©:") or lines[j].strip().startswith("ë¬¸ì„œ")):
                    metadata_lines.append(lines[j])
                    j += 1
        
        metadata_only = "\n".join(metadata_lines)
        
        system_prompt = PROMPT_TEMPLATE.format(question=question, context=metadata_only)
        
        # OpenAI API í˜¸ì¶œí•˜ì—¬ ë‹µë³€ ìƒì„±
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": question}
            ],
            temperature=0.3,
            max_tokens=2000
        )
        
        answer_content = response.choices[0].message.content
        
        # ìš”ì²­ê³¼ ì‘ë‹µì„ ë¡œê·¸ íŒŒì¼ì— ì €ì¥
        log_file = log_gpt_interaction(
            question=question,
            context=context,
            model=model,
            response=answer_content,
            metadata_only=metadata_only,
            system_prompt=system_prompt  # ì‹¤ì œ GPTì—ê²Œ ì „ì†¡ëœ system í”„ë¡¬í”„íŠ¸ ì¶”ê°€
        )
        
        # ë¡œê·¸ ì €ì¥ ì•Œë¦¼
        st.info(f"GPT ìš”ì²­/ì‘ë‹µì´ ë‹¤ìŒ íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {log_file}")
        
        return answer_content
    except Exception as e:
        return f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

def get_xlsx_files():
    """
    data/xlsx ë””ë ‰í† ë¦¬ì—ì„œ ëª¨ë“  ì—‘ì…€ íŒŒì¼ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    xlsx_dir = "./data/xlsx"
    os.makedirs(xlsx_dir, exist_ok=True)
    
    xlsx_files = [f for f in os.listdir(xlsx_dir) if f.endswith('.xlsx')]
    return xlsx_files

def get_faiss_files():
    """
    data/vdb ë””ë ‰í† ë¦¬ì—ì„œ ëª¨ë“  FAISS ì¸ë±ìŠ¤ íŒŒì¼ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    vdb_dir = "./data/vdb"
    os.makedirs(vdb_dir, exist_ok=True)
    
    faiss_files = [f for f in os.listdir(vdb_dir) if f.endswith('.faiss')]
    return faiss_files

def main():
    # ì œëª©
    st.title("ğŸ” FAISS ë²¡í„° ì €ì¥ì†Œ íƒìƒ‰ê¸°")
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    st.sidebar.title("ì„¤ì •")
    
    # API í‚¤ ì„¤ì •
    api_key = st.sidebar.text_input("OpenAI API í‚¤", 
                                   value=os.environ.get("OPENAI_API_KEY", ""), 
                                   type="password")
    
    if api_key:
        st.session_state['api_key'] = api_key
        os.environ["OPENAI_API_KEY"] = api_key
    
    # OpenAI ëª¨ë¸ ì„ íƒ
    model_options = ["gpt-4o", "gpt-4-turbo", "gpt-3.5-turbo"]
    selected_model = st.sidebar.selectbox("OpenAI ëª¨ë¸ ì„ íƒ", model_options)
    
    # ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs("./data/xlsx", exist_ok=True)
    os.makedirs("./data/vdb", exist_ok=True)
    
    # íŒŒì¼ ì„¤ì •
    st.sidebar.subheader("íŒŒì¼ ì„¤ì •")
    
    # ì—‘ì…€ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    xlsx_files = get_xlsx_files()
    
    # ì§ì ‘ ì…ë ¥ ë˜ëŠ” ë“œë¡­ë‹¤ìš´ ì„ íƒ ì˜µì…˜
    file_selection_mode = st.sidebar.radio("íŒŒì¼ ì„ íƒ ë°©ì‹", ["ë“œë¡­ë‹¤ìš´ì—ì„œ ì„ íƒ", "ì§ì ‘ ê²½ë¡œ ì…ë ¥"])
    
    if file_selection_mode == "ë“œë¡­ë‹¤ìš´ì—ì„œ ì„ íƒ":
        if xlsx_files:
            selected_xlsx = st.sidebar.selectbox(
                "Excel íŒŒì¼ ì„ íƒ", 
                xlsx_files,
                index=0 if xlsx_files else None,
                format_func=lambda x: x
            )
            input_file = os.path.join("./data/xlsx", selected_xlsx) if selected_xlsx else ""
        else:
            st.sidebar.warning("./data/xlsx ë””ë ‰í† ë¦¬ì— Excel íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            input_file = ""
            
        # FAISS ì¸ë±ìŠ¤ íŒŒì¼ ëª©ë¡
        faiss_files = get_faiss_files()
        
        if faiss_files:
            # ì„ íƒëœ Excel íŒŒì¼ì— ëŒ€ì‘í•˜ëŠ” FAISS íŒŒì¼ ì°¾ê¸°
            if input_file:
                base_name_without_ext = os.path.splitext(os.path.basename(input_file))[0]
                matching_faiss = [f for f in faiss_files if f.startswith(base_name_without_ext)]
                
                # ê¸°ë³¸ ì„ íƒê°’ ì„¤ì •
                default_index = 0
                if matching_faiss:
                    default_index = faiss_files.index(matching_faiss[0])
                
                selected_faiss = st.sidebar.selectbox(
                    "FAISS ì¸ë±ìŠ¤ íŒŒì¼ ì„ íƒ",
                    faiss_files,
                    index=default_index if faiss_files else None,
                    format_func=lambda x: x
                )
                index_file = os.path.join("./data/vdb", selected_faiss) if selected_faiss else ""
            else:
                selected_faiss = st.sidebar.selectbox(
                    "FAISS ì¸ë±ìŠ¤ íŒŒì¼ ì„ íƒ",
                    faiss_files,
                    index=0 if faiss_files else None,
                    format_func=lambda x: x
                )
                index_file = os.path.join("./data/vdb", selected_faiss) if selected_faiss else ""
        else:
            st.sidebar.warning("./data/vdb ë””ë ‰í† ë¦¬ì— FAISS ì¸ë±ìŠ¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            index_file = ""
    else:
        # ì§ì ‘ ê²½ë¡œ ì…ë ¥ ëª¨ë“œ
        input_file = st.sidebar.text_input("Excel íŒŒì¼ ê²½ë¡œ", "./data/xlsx/output_20250326_111000.xlsx")
        
        # ì¸ë±ìŠ¤ íŒŒì¼ì€ ì—‘ì…€ íŒŒì¼ ì´ë¦„ì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ë˜, ./data/vdb ë””ë ‰í† ë¦¬ì— ì €ì¥
        base_filename = os.path.basename(input_file)
        base_name_without_ext = os.path.splitext(base_filename)[0]
        index_file = st.sidebar.text_input(
            "FAISS ì¸ë±ìŠ¤ íŒŒì¼ ê²½ë¡œ", 
            f"./data/vdb/{base_name_without_ext}.faiss" if input_file else "./data/vdb/embeddings.faiss"
        )
    
    # íƒ­ ìƒì„±
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“Š ë°ì´í„° ë¡œë“œ", "âš™ï¸ ì¸ë±ìŠ¤ ìƒì„±/ë¡œë“œ", "ğŸ” ê²€ìƒ‰", "ğŸ¤– RAG ë‹µë³€ ìƒì„±"])
    
    # íƒ­ 1: ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
    with tab1:
        st.header("ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
        
        if st.button("ë°ì´í„° ë¡œë“œ"):
            if not os.path.exists(input_file):
                st.error(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_file}")
            else:
                try:
                    df = pd.read_excel(input_file)
                    st.session_state['df'] = df
                    
                    st.success(f"{len(df)}ê°œ í–‰ì„ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
                    st.subheader("ë°ì´í„° ìƒ˜í”Œ")
                    st.dataframe(df.head())
                    
                    # ì»¬ëŸ¼ ì •ë³´ í‘œì‹œ
                    st.subheader("ì»¬ëŸ¼ ì •ë³´")
                    col_info = pd.DataFrame({
                        "ì»¬ëŸ¼ëª…": df.columns,
                        "ë°ì´í„° íƒ€ì…": df.dtypes,
                        "NULL ê°’ ìˆ˜": df.isnull().sum().values,
                        "ê³ ìœ ê°’ ìˆ˜": [df[col].nunique() for col in df.columns]
                    })
                    st.dataframe(col_info)
                    
                except Exception as e:
                    st.error(f"Excel íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
    
    # íƒ­ 2: ì¸ë±ìŠ¤ ìƒì„± ë˜ëŠ” ë¡œë“œ
    with tab2:
        st.header("ì¸ë±ìŠ¤ ìƒì„± ë˜ëŠ” ë¡œë“œ")
        
        # ì„ íƒí•œ Excel íŒŒì¼ì˜ FAISS ì¸ë±ìŠ¤ íŒŒì¼ì´ ì—†ëŠ”ì§€ í™•ì¸í•˜ëŠ” ë©”ì‹œì§€ í‘œì‹œ
        if input_file and os.path.exists(input_file):
            base_name_without_ext = os.path.splitext(os.path.basename(input_file))[0]
            expected_faiss_file = os.path.join("./data/vdb", f"{base_name_without_ext}.faiss")
            
            if not os.path.exists(expected_faiss_file):
                st.warning(f"ì„ íƒí•œ Excel íŒŒì¼({os.path.basename(input_file)})ì— ëŒ€ì‘í•˜ëŠ” FAISS ì¸ë±ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. 'ì¸ë±ìŠ¤ ìƒì„±' ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ìƒì„±í•´ì£¼ì„¸ìš”.")
        
        col1, col2 = st.columns(2)
        with col1:
            create_button = st.button("ì¸ë±ìŠ¤ ìƒì„±", key="create_index_button")
        with col2:
            load_button = st.button("ì¸ë±ìŠ¤ ë¡œë“œ", key="load_index_button")
        
        if create_button or load_button:
            if not os.path.exists(input_file):
                st.error(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_file}")
            elif not api_key:
                st.error("OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                # ë²¡í„° ì €ì¥ì†Œ ì´ˆê¸°í™”
                vector_store = FAISSVectorStore()
                
                # ì„ë² ë”© ë¡œë“œ ë˜ëŠ” ìƒì„±
                if create_button:
                    # Excel íŒŒì¼ ê¸°ë°˜ìœ¼ë¡œ ìƒˆ ì¸ë±ìŠ¤ ìƒì„± ì‹œ ê¸°ì¡´ ì¸ë±ìŠ¤ íŒŒì¼ì€ ë¬´ì‹œ
                    success = vector_store.load_embeddings(input_file, index_file, force_recreate=True)
                else:
                    # ë¡œë“œë§Œ í•  ê²½ìš°, ì¸ë±ìŠ¤ íŒŒì¼ì´ ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ ìƒì„±
                    if not os.path.exists(index_file):
                        st.warning(f"ì¸ë±ìŠ¤ íŒŒì¼ì´ ì—†ì–´ Excel íŒŒì¼ë¡œë¶€í„° ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤: {index_file}")
                    success = vector_store.load_embeddings(input_file, index_file)
                
                if success:
                    st.session_state['vector_store'] = vector_store
                    
                    # ì¸ë±ìŠ¤ ì •ë³´ í‘œì‹œ
                    st.subheader("ì¸ë±ìŠ¤ ì •ë³´")
                    st.write(f"ë²¡í„° ìˆ˜: {vector_store.index.ntotal}")
                    st.write(f"ë²¡í„° ì°¨ì›: {vector_store.dimension}")
                    st.write(f"ë¬¸ì„œ ìˆ˜: {len(vector_store.contents)}")
                    
                    # ì²« ë²ˆì§¸ ë¬¸ì„œ ìƒ˜í”Œ í‘œì‹œ
                    if len(vector_store.contents) > 0:
                        st.subheader("ì²« ë²ˆì§¸ ë¬¸ì„œ ìƒ˜í”Œ")
                        st.text_area(label="ë¬¸ì„œ ë‚´ìš©", value=vector_store.contents[0], height=150)
                        st.markdown("**ë©”íƒ€ë°ì´í„°:**")
                        st.markdown(format_metadata(vector_store.metadata[0]))
    
    # íƒ­ 3: ê²€ìƒ‰
    with tab3:
        st.header("ê²€ìƒ‰")
        
        query = st.text_input("ê²€ìƒ‰ì–´ ì…ë ¥", "", key="search_query_input")
        top_k = st.slider("ê²€ìƒ‰ ê²°ê³¼ ìˆ˜", min_value=1, max_value=20, value=5, key="search_top_k_slider")
        
        if st.button("ê²€ìƒ‰", key="search_button") and query:
            if 'vector_store' not in st.session_state:
                st.error("ë¨¼ì € 'ì¸ë±ìŠ¤ ìƒì„±/ë¡œë“œ' íƒ­ì—ì„œ ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•˜ê±°ë‚˜ ë¡œë“œí•´ì£¼ì„¸ìš”.")
            elif not api_key:
                st.error("OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
                vector_store = st.session_state['vector_store']
                query_embedding = get_embedding(query)
                
                # ê²€ìƒ‰
                results = vector_store.search(query_embedding, top_k)
                
                # ê²°ê³¼ í‘œì‹œ
                if results:
                    st.subheader(f"ê²€ìƒ‰ ê²°ê³¼ ({len(results)}ê°œ)")
                    
                    for i, result in enumerate(results):
                        with st.expander(f"ê²°ê³¼ {i+1} (ìœ ì‚¬ë„: {result['similarity']:.4f})"):
                            st.markdown("**ë‚´ìš©:**")
                            st.text_area(label="ë¬¸ì„œ ë‚´ìš©", value=result['content'], height=150, key=f"content_{i}")
                            
                            st.markdown("**ë©”íƒ€ë°ì´í„°:**")
                            st.markdown(format_metadata(result['metadata']))
                else:
                    st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    # íƒ­ 4: RAG ë‹µë³€ ìƒì„±
    with tab4:
        st.header("RAG ë‹µë³€ ìƒì„±")
        
        question = st.text_area("ì§ˆë¬¸ ì…ë ¥", "", height=100, key="rag_question_input")
        top_k = st.slider("ê²€ìƒ‰ ê²°ê³¼ ìˆ˜", min_value=1, max_value=20, value=5, key="rag_top_k_slider")
        
        col1, col2 = st.columns(2)
        with col1:
            generate_button = st.button("ë‹µë³€ ìƒì„±", key="rag_generate_button")
        with col2:
            clear_button = st.button("ì´ˆê¸°í™”", key="rag_clear_button")
        
        if clear_button:
            if 'rag_results' in st.session_state:
                del st.session_state['rag_results']
            if 'rag_answer' in st.session_state:
                del st.session_state['rag_answer']
        
        if generate_button and question:
            if 'vector_store' not in st.session_state:
                st.error("ë¨¼ì € 'ì¸ë±ìŠ¤ ìƒì„±/ë¡œë“œ' íƒ­ì—ì„œ ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•˜ê±°ë‚˜ ë¡œë“œí•´ì£¼ì„¸ìš”.")
            elif not api_key:
                st.error("OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                with st.spinner("ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ëŠ” ì¤‘..."):
                    # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
                    vector_store = st.session_state['vector_store']
                    query_embedding = get_embedding(question)
                    
                    # ê²€ìƒ‰
                    results = vector_store.search(query_embedding, top_k)
                    st.session_state['rag_results'] = results
                
                if results:
                    # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
                    context = ""
                    for i, result in enumerate(results):
                        context += f"ë¬¸ì„œ {i+1}:\n"
                        context += f"ë‚´ìš©: {result['content']}\n"
                        context += f"ë©”íƒ€ë°ì´í„°: {result['metadata']}\n\n"
                    
                    # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
                    client = OpenAI(api_key=api_key)
                    
                    with st.spinner("GPT-4oë¡œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘..."):
                        answer = generate_answer(question, context, client, model=selected_model)
                        st.session_state['rag_answer'] = answer
                else:
                    st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì§ˆë¬¸ì„ ì‹œë„í•´ ë³´ì„¸ìš”.")
        
        # ê²°ê³¼ í‘œì‹œ ì„¹ì…˜
        if 'rag_results' in st.session_state and 'rag_answer' in st.session_state:
            # ë‹µë³€ í‘œì‹œ
            st.subheader("ìƒì„±ëœ ë‹µë³€")
            st.markdown(st.session_state['rag_answer'])
            
            # ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ
            st.subheader("ì‚¬ìš©ëœ ì°¸ê³  ë¬¸ì„œ")
            for i, result in enumerate(st.session_state['rag_results']):
                with st.expander(f"ë¬¸ì„œ {i+1} (ìœ ì‚¬ë„: {result['similarity']:.4f})"):
                    st.markdown("**ë‚´ìš©:**")
                    st.text_area(label="ë¬¸ì„œ ë‚´ìš©", value=result['content'], height=150, key=f"rag_content_{i}")
                    
                    st.markdown("**ë©”íƒ€ë°ì´í„°:**")
                    st.markdown(format_metadata(result['metadata']))

if __name__ == "__main__":
    main() 